Lambda란?
 • AWS Lambda:  서버를 직접 관리하지 않고, 코드를 실행할 수 
있게 해주는 서비스
• 서버 필요 없음: EC2 인스턴스처럼 서버 띄우고 관리할 필요X.
 • 초 단위 과금: 실제 코드가 돌아간 시간만 지불
• 자동 확장: 호출이 많아지면 Lambda가 자동으로 인스턴스 확장
• 이벤트 기반 실행: S3 파일 업로드, DynamoDB 변경, API Gateway 호출 등 다양한 이벤트로 동작 가능
• 다양한 언어 지원 : Python, Node.js, Java, Go 등 

S3에서 가져와서 업로드
import json  # JSON 형식으로 응답을 구성하기 위한 모듈
import boto3  # AWS 서비스(S3 등)를 사용하기 위한 SDK
from datetime import datetime  # 현재 시간 정보를 얻기 위한 모듈

def lambda_handler(event, context):
    # S3 클라이언트 생성 (S3에 접근하기 위한 boto3 객체)
    s3 = boto3.client('s3')

    # 업로드할 대상 버킷 이름
    bucket_name = 'sgu-202500-3b'

    # 파일을 저장할 S3 key prefix (디렉토리처럼 동작함)
    prefix = 'uploaded/'

    # 현재 시간을 문자열로 포맷 (파일 이름에 포함시킬 용도)
    now = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')

    # 파일 이름 생성: 예) uploaded/hello_2025-06-11_14-00-00.txt
    filename = f'{prefix}hello_{now}.txt'

    # 파일 내용 구성
    content = f'Hello Haeri! This file was created at {now}'

    # S3에 파일 업로드
    s3.put_object(
        Bucket=bucket_name,               # 업로드할 버킷 이름
        Key=filename,                     # 파일 경로 및 이름
        Body=content.encode('utf-8')      # 파일의 실제 내용 (UTF-8로 인코딩)
    )

    # Application Load Balancer(ALB) 또는 API Gateway가 기대하는 형식으로 응답 반환
    return {
        "statusCode": 200,                        # HTTP 상태 코드
        "statusDescription": "200 OK",            # 상태 설명 (선택 항목)
        "isBase64Encoded": False,                 # 응답이 base64로 인코딩되었는지 여부 (텍스트는 False)
        "headers": {
            "Content-Type": "application/json"    # 응답 헤더에 JSON 콘텐츠 타입 지정
        },
        "body": json.dumps({
            "message": "업로드 완료",              # 실제 응답 메시지
            "filename": filename                   # 업로드된 파일 이름도 함께 반환
        }, ensure_ascii=False)
    }

다이나모 디비 첫 입력 값 종류 1개라도 있으면 추가댐
[
  {
    "user_id": { "S": "haeri05" },
    "product_name": { "S": "무선 이어폰" },
    "category": { "S": "디지털" },
    "reason": { "S": "최근 블루투스 기기 검색" },
    "timestamp": { "S": "2025-05-11T21:00:00" },
    "price": { "N": "89000" },
    "brand": { "S": "소니" },
    "color": { "S": "블랙" },
    "rating": { "N": "4.7" }
  },
  {
    "user_id": { "S": "minji01" },
    "product_name": { "S": "핑크 가습기" },
    "category": { "S": "생활가전" },
    "timestamp": { "S": "2025-05-11T21:01:00" }
  },
  {
    "user_id": { "S": "jihoon07" },
    "product_name": { "S": "텀블러" }
  },
  {
    "user_id": { "S": "yuna23" },
    "product_name": { "S": "토끼 인형" },
    "reason": { "S": "장난감 카테고리 체류시간 높음" }
  }
]

추가
INSERT INTO "sgu-202500-user-likes" (user_id, product_name)
VALUES ('jihoon07', '코카콜라');

덮어쓰기
import boto3

def lambda_handler(event, context):
    # DynamoDB 리소스 생성
    dynamodb = boto3.resource('dynamodb')
    # 테이블 선택
    table = dynamodb.Table('sgu-202500-user-likes')

    # 덮어쓰기(put)할 아이템 정의
    response = table.put_item(
        Item={
            'user_id': 'jihoon07',
            'product_name': '제로콜라'
        }
    )

    # 성공 응답 반환
    return {
        'statusCode': 200,
        'body': 'PutItem successful!'
    }

postman 가능(lamdba)

import boto3
import json
from datetime import datetime

def lambda_handler(event, context):
    try:
        # 1. 요청 본문에서 JSON 데이터 파싱
        body = json.loads(event['body'])
        user_id = body['user_id']
        product = body['product']
        timestamp = datetime.now().isoformat()

        # 2. 선택적 필드들 추출 (없으면 None)
        reason = body.get('reason')
        brand = body.get('brand')
        price = body.get('price')
        color = body.get('color')

        # 3. DynamoDB에 저장할 항목 구성
        item = {
            'user_id': user_id,
            'timestamp': timestamp,
            'product': product
        }

        # 4. 선택 필드가 있으면 item에 추가
        if reason:
            item['reason'] = reason
        if brand:
            item['brand'] = brand
        if price:
            item['price'] = price
        if color:
            item['color'] = color

        # 5. DynamoDB 테이블 객체 생성 및 데이터 저장
        table = boto3.resource('dynamodb').Table('sgu-202500-user-likes-time')
        table.put_item(Item=item)

        # 6. 성공 응답 반환
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': '저장 완료',
                'user_id': user_id,
                'timestamp': timestamp
            }, ensure_ascii=False)
        }

    except Exception as e:
        # 예외 발생 시 에러 메시지 반환
        return {
            'statusCode': 400,
            'body': json.dumps({'error': str(e)}, ensure_ascii=False)
        }

s3://sgu-202500-3b/dynamo_data/user_likes_data.json
 user_likes_data.json
 {
 "user_id": "haeri05",
 "product": "워치",
 "price": 50000,
 "brand": "애플"
 }

s3의 전체 파일 가져오기
import json
import boto3
from datetime import datetime

def lambda_handler(event, context):
    # AWS 서비스(S3, DynamoDB) 클라이언트 및 리소스 생성
    s3 = boto3.client('s3')  # S3 클라이언트 생성
    dynamodb = boto3.resource('dynamodb')  # DynamoDB 리소스 객체 생성
    table = dynamodb.Table('sgu-202500-user-likes-time')  # 사용할 DynamoDB 테이블 지정

    # S3에서 가져올 버킷 이름과 객체(Key) 지정
    bucket_name = 'sgu-202500-3b'
    object_key = 'dynamo_data/user_likes_data.json'

    try:
        # S3에서 JSON 파일 가져오기
        response = s3.get_object(Bucket=bucket_name, Key=object_key)

        # 파일 내용 읽고 문자열로 디코딩
        content = response['Body'].read().decode('utf-8')

        # 문자열을 JSON 형식으로 파싱
        data = json.loads(content)

        # 현재 시각 타임스탬프를 ISO 8601 형식으로 추가
        timestamp = datetime.now().isoformat()
        data['timestamp'] = timestamp

        # 파싱된 데이터를 DynamoDB 테이블에 삽입
        table.put_item(Item=data)

        # 성공 응답 반환
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'DynamoDB insert successful!',
                'item': data
            }, ensure_ascii=False)
        }

    except Exception as e:
        # 오류 발생 시 에러 메시지와 함께 500 응답 반환
        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': str(e)
            }, ensure_ascii=False)
        }


S3의 user_id와 product만 가져오기
import json
import boto3
from datetime import datetime

def lambda_handler(event, context):
    # AWS S3 클라이언트 및 DynamoDB 리소스 생성
    s3 = boto3.client('s3')
    dynamodb = boto3.resource('dynamodb')
    table = dynamodb.Table('sgu-202500-user-likes-time')  # 사용할 DynamoDB 테이블 지정

    # S3에서 가져올 버킷 이름과 파일 키 설정
    bucket_name = 'sgu-202500-3b'
    object_key = 'dynamo_data/user_likes_data_2.json'

    try:
        # 1. S3에서 JSON 파일 가져오기
        response = s3.get_object(Bucket=bucket_name, Key=object_key)
        content = response['Body'].read().decode('utf-8')
        raw_data = json.loads(content)

        # 2. 필요한 필드(user_id, product)만 추출
        user_id = raw_data.get('user_id')
        product = raw_data.get('product')

        # 필수 필드 누락 시 오류 반환
        if not user_id or not product:
            return {
                'statusCode': 400,
                'body': '필수 데이터 누락: user_id 또는 product가 없습니다.'
            }

        # 3. DynamoDB에 저장할 항목 구성
        item = {
            'user_id': user_id,
            'timestamp': datetime.now().isoformat(),  # 현재 시각 타임스탬프 추가
            'product': product
        }

        # 4. 항목을 DynamoDB에 삽입
        table.put_item(Item=item)

        # 5. 성공 응답 반환
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': '선택 필드만 Insert 완료',
                'item': item
            }, ensure_ascii=False)
        }

    except Exception as e:
        # 예외 발생 시 에러 메시지 포함 응답 반환
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)}, ensure_ascii=False)
        }


[
 {
 "user_id": "haeri01",
 "product": "갤럭시워치",
 "price": 40000,
 "brand": "삼성"
 },
 {
 "user_id": "minji02",
 "product": "아이패드",
 "price": 800000,
 "brand": "애플"
 },
 {
 "user_id": "jihoon03",
 "product": "버즈",
 "price": 120000,
 "brand": "삼성"
 }
]

배열 형식으로 되어 있을 경우
import json
import boto3
from datetime import datetime

def lambda_handler(event, context):
    # S3 클라이언트 및 DynamoDB 리소스 생성
    s3 = boto3.client('s3')
    dynamodb = boto3.resource('dynamodb')
    table = dynamodb.Table('sgu-202500-user-likes-time')  # DynamoDB 테이블 지정

    # 대상 S3 버킷과 객체 키 설정
    bucket_name = 'sgu-202500-3b'
    object_key = 'dynamo_data/user_likes_data.json'

    try:
        # 1. S3에서 파일 읽기
        response = s3.get_object(Bucket=bucket_name, Key=object_key)
        content = response['Body'].read().decode('utf-8')
        data_list = json.loads(content)  # JSON 배열 파싱

        # 2. 각 항목에 대해 반복 처리
        for record in data_list:
            user_id = record.get('user_id')
            product = record.get('product')

            # 필수 필드 누락 시 무시하고 다음 항목으로
            if not user_id or not product:
                print(f"user_id 또는 product 누락: {record}")
                continue

            # 저장할 항목 구성
            item = {
                'user_id': user_id,
                'timestamp': datetime.now().isoformat(),  # 현재 시각
                'product': product
            }

            # DynamoDB에 항목 저장
            table.put_item(Item=item)
            print(f"Inserted: {item}")

        # 모든 레코드 처리 후 성공 응답 반환
        return {
            'statusCode': 200,
            'body': json.dumps('전체 레코드 Insert 완료', ensure_ascii=False)
        }

    except Exception as e:
        # 예외 발생 시 에러 메시지 포함 응답 반환
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)}, ensure_ascii=False)
        }

클라우드 워치 조회용
import boto3
import json
from datetime import datetime

def lambda_handler(event, context):
    # CloudWatch Logs 클라이언트 및 DynamoDB 리소스 생성
    logs = boto3.client('logs')
    dynamodb = boto3.resource('dynamodb')
    table = dynamodb.Table('sgu-202500-user-likes-time')  # 사용할 DynamoDB 테이블 지정

    log_group = '/aws/lambda/sgu-202500-lambda-s3'  # 로그 그룹 이름

    try:
        # 1. 가장 최근의 로그 스트림 가져오기
        streams = logs.describe_log_streams(
            logGroupName=log_group,
            orderBy='LastEventTime',
            descending=True,
            limit=1
        )['logStreams']

        # 로그 스트림이 없으면 404 반환
        if not streams:
            return {
                'statusCode': 404,
                'body': 'No log streams found'
            }

        # 가장 최근 로그 스트림 이름 추출
        stream_name = streams[0]['logStreamName']

        # 2. 해당 로그 스트림에서 최근 로그 이벤트 20개 가져오기
        events = logs.get_log_events(
            logGroupName=log_group,
            logStreamName=stream_name,
            limit=20,
            startFromHead=True
        )['events']

        # 3. 로그 이벤트를 하나씩 DynamoDB에 저장
        for e in events:
            # CloudWatch의 timestamp는 ms 단위 → datetime 객체로 변환 후 ISO 포맷으로 변경
            event_time = datetime.fromtimestamp(e['timestamp'] / 1000).isoformat()
            message = e['message'].strip()

            # 저장할 항목 구성
            item = {
                'user_id': 'cloudwatch',  # 고정값
                'timestamp': event_time,  # 로그 발생 시간
                'product': message        # 로그 메시지 내용
            }

            # DynamoDB에 삽입
            table.put_item(Item=item)
            print(f"Inserted: {item}")

        # 모든 로그 저장 후 성공 응답 반환
        return {
            'statusCode': 200,
            'body': json.dumps('CloudWatch 로그 → DynamoDB 저장 완료', ensure_ascii=False)
        }

    except Exception as e:
        # 예외 발생 시 에러 메시지 반환
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)}, ensure_ascii=False)
        }

